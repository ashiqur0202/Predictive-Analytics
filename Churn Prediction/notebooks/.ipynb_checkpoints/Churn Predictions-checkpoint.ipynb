{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e5ad189-aff2-4339-88c7-944f6150d15a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d71aa165-c621-4143-9680-6ecdd758f45b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def import_churn_libraries():\n",
    "    \"\"\"\n",
    "    Import commonly used libraries and packages for churn prediction.\n",
    "\n",
    "    Returns:\n",
    "    - pd: Data manipulation library.\n",
    "    - np: Numerical operations library.\n",
    "    - plt: Plotting library.\n",
    "    - sns: Data visualization library.\n",
    "    - train_test_split: Library for model selection.\n",
    "    - StandardScaler: Library for data preprocessing.\n",
    "    - RandomForestClassifier: Random Forest classifier.\n",
    "    - accuracy_score: Library for model evaluation metrics.\n",
    "    - confusion_matrix: Library for model evaluation metrics.\n",
    "    - classification_report: Library for model evaluation metrics.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "    return pd, np, plt, sns, train_test_split, StandardScaler, RandomForestClassifier, accuracy_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e30af140-9f12-4db1-8f77-2f73e4fba3a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd, np, plt, sns, train_test_split, StandardScaler, RandomForestClassifier, accuracy_score, confusion_matrix, classification_report = import_churn_libraries()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea73e7a-0ebb-4d53-8bac-01714d3a36f0",
   "metadata": {},
   "source": [
    "### 0. Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f23a710-ce24-4310-8f94-5252fdacc4ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    # Assuming your data is in a CSV file, adjust accordingly for other formats\n",
    "    data = pd.read_csv(file_path)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d3099c-4919-4eab-bc56-2d98203d36ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = \"../data/raw/new_raw.csv\"\n",
    "\n",
    "data = load_data(file_path)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad76eab-a33e-4037-95ef-82c90ac0076a",
   "metadata": {},
   "source": [
    "### 1. Data Preprocessing Function:\n",
    "- Handle missing values.\n",
    "- Encode categorical variables.\n",
    "- Scale or normalize features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e10cb27-b9f0-4173-8f1e-8e1c0b718af6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data Preprocessing Function\n",
    "def preprocess_data(data):\n",
    "    # Droping Unnamed: 0 columns\n",
    "    data = data.drop(columns=\"Unnamed: 0\")\n",
    "\n",
    "    # Checking for data integrity\n",
    "    # For example, ensuring 'txn_date' is in the correct format\n",
    "    data['txn_date'] = pd.to_datetime(data['txn_date'], errors='coerce')\n",
    "\n",
    "    # Handling outliers in 'txn_amount'\n",
    "    Q1 = data['txn_amount'].quantile(0.25)\n",
    "    Q3 = data['txn_amount'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    data = data[(data['txn_amount'] >= lower_bound) & (data['txn_amount'] <= upper_bound)]\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfb3aab-0aea-4e7d-8292-6863e0fcfd72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Preprocess data\n",
    "# df_preprocessed = preprocess_data(data)\n",
    "\n",
    "# df_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d2d3e0-da20-40be-a5c2-9912bafa3dbb",
   "metadata": {},
   "source": [
    "### 2. Feature Engineering Function:\n",
    "- Create new features.\n",
    "- Transform existing features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0758508d-bd2c-4609-8b88-c31ba0a08f7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def feature_engineering(df_preprocessed):\n",
    "    # Extract day from 'txn_date'\n",
    "    df_preprocessed['txn_day'] = pd.to_datetime(df_preprocessed['txn_date']).dt.day\n",
    "    \n",
    "    # Extract month from 'txn_date'\n",
    "    df_preprocessed['txn_month'] = pd.to_datetime(df_preprocessed['txn_date']).dt.month\n",
    "    \n",
    "    # Assuming 'txn_type' is categorical, perform one-hot encoding\n",
    "    df_preprocessed = pd.concat([df_preprocessed, pd.get_dummies(df_preprocessed['txn_type'], prefix='txn_type').astype(int)], axis=1)\n",
    "\n",
    "    # Dropping unnecessary columns\n",
    "    #df_preprocessed = df_preprocessed.drop(['txn_date', 'txn_type'], axis=1)\n",
    "\n",
    "    return df_preprocessed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5323543-b781-4380-98c6-bb2c211b5c86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_preprocessed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf_preprocessed\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_preprocessed' is not defined"
     ]
    }
   ],
   "source": [
    "df_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04118ee7-6114-412a-9982-2ed3b9c31204",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Assuming df_preprocessed is your preprocessed DataFrame\n",
    "# df_engineered = feature_engineering(df_preprocessed)\n",
    "\n",
    "# # Display the resulting DataFrame\n",
    "# df_engineered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bd13e9b-f4d3-4db8-a9d5-fe655989781a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "def add_churn_column(df_engineered, churn_window_days=90):\n",
    "    \"\"\"\n",
    "    Add a 'churn' column to the DataFrame based on the calculated churn date.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame with 'txn_date' column.\n",
    "    - churn_window_days (int): Number of days to consider for churn (default is 90).\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with the added 'churn' column.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Convert 'txn_date' to datetime format if not already\n",
    "    df_engineered['txn_date'] = pd.to_datetime(df_engineered['txn_date'])\n",
    "\n",
    "    # Sort the DataFrame by 'txn_date'\n",
    "    df_engineered = df_engineered.sort_values(by='txn_date')\n",
    "\n",
    "    # Calculate the hypothetical churn date\n",
    "    last_txn_date = df_engineered['txn_date'].max()\n",
    "    churn_date = last_txn_date - timedelta(days=churn_window_days)\n",
    "\n",
    "    # Create 'churn' column based on the calculated churn date\n",
    "    df_engineered['churn'] = (df_engineered['txn_date'] <= churn_date).astype(int)\n",
    "    return df_engineered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e9e91c-cf8e-4ca9-b42d-854b08306ea2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_churned = add_churn_column(df_engineered)\n",
    "# df_churned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e6eaee-844f-4459-804c-b6c4178553eb",
   "metadata": {},
   "source": [
    "### 3. Train-Test Split Function:\n",
    "- Split the dataset into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2359153-c72b-41e6-bd82-9c4de08c2b3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#df_churned = df_engineered.copy()\n",
    "# features = df_churned[['account_number', 'txn_amount', 'txn_month',\n",
    "#        'txn_day', 'txn_type_add_money', 'txn_type_cash_in',\n",
    "#        'txn_type_cash_out', 'txn_type_payment', 'txn_type_send_money',\n",
    "#        'churn']]\n",
    "\n",
    "# target = 'churn'\n",
    "\n",
    "def split_data(data, target_column='churn'):\n",
    "    # Extract features and target variable\n",
    "    X = data.drop(target_column, axis=1)  # Assuming 'churn' is the target column\n",
    "    y = data[target_column]\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d70885b-1fcc-4ae6-8c45-976fd8328312",
   "metadata": {},
   "source": [
    "### 4. Model Selection and Training Function:\n",
    "- Choose a machine learning model.\n",
    "- Train the selected model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e6ba2c8-8fc0-430a-8914-0790f17ede6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def train_model(model, X_train, y_train):\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee34709c-eea8-41bf-b92d-9cc6e92c065b",
   "metadata": {},
   "source": [
    "### 5. Model Evaluation Function:\n",
    "- Make predictions on the test set.\n",
    "- Evaluate the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfe41577-4683-4e0d-9b06-8bd7411a1653",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Generate confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Generate classification report\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "    return accuracy, conf_matrix, class_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b93a276-8a43-49ca-92a8-812a0e2b5337",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# accuracy, conf_matrix, class_report = evaluate_model(trained_model, X_test, y_test)\n",
    "\n",
    "# # Display the results\n",
    "# print(f\"Model Accuracy: {accuracy}\")\n",
    "# print(\"\\nConfusion Matrix:\")\n",
    "# print(conf_matrix)\n",
    "# print(\"\\nClassification Report:\")\n",
    "# print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2967e6f9-b2db-4283-8b90-2477a05f1a0f",
   "metadata": {},
   "source": [
    "### 6. Hyperparameter Tuning Function (Optional):\n",
    "- Tune hyperparameters for better model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1621eff6-acda-4a12-8d79-87bd6bea35e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# def tune_hyperparameters(base_model, param_grid, X_train, y_train):\n",
    "#     # Initialize Grid Search with the base model and parameter grid\n",
    "#     grid_search = GridSearchCV(base_model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "#     # Fit the grid search to the data\n",
    "#     grid_search.fit(X_train, y_train)\n",
    "\n",
    "#     # Get the best-tuned model\n",
    "#     tuned_model = grid_search.best_estimator_\n",
    "\n",
    "#     return tuned_model\n",
    "\n",
    "# # Example parameter grid for RandomForestClassifier\n",
    "# param_grid_rf = {\n",
    "#     'n_estimators': [50, 100, 200],\n",
    "#     'max_depth': [None, 10, 20],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4]\n",
    "# }\n",
    "\n",
    "# # Assuming X_train and y_train are obtained from the split_data function\n",
    "# # Assuming trained_model is the initial RandomForest model trained in your previous step\n",
    "# tuned_model_rf = tune_hyperparameters(trained_model, param_grid_rf, X_train, y_train)\n",
    "\n",
    "# # Now you can use tuned_model_rf for evaluation or further steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72acbd9b-c4ba-46b1-b360-e83f0bd142e6",
   "metadata": {},
   "source": [
    "### Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "243c1189-e318-4872-9768-8abdff39fe35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save_model.py\n",
    "\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "def save_model(model, model_name, directory=\"models\"):\n",
    "    \"\"\"\n",
    "    Save a machine learning model with a timestamped filename.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The trained machine learning model.\n",
    "    - model_name: The name of the model (e.g., \"RandomForestClassifier\").\n",
    "    - directory: The directory where the model will be saved.\n",
    "    \"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    file_path = f\"{directory}/{model_name}_{timestamp}.pkl\"\n",
    "\n",
    "    try:\n",
    "        joblib.dump(model, file_path)\n",
    "        print(f\"Model saved successfully to {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving the model: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d3a59f-f3e9-4d55-9b9f-251439532e7f",
   "metadata": {},
   "source": [
    "### 7. Main Function:\n",
    "- Orchestrates the entire modeling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7b785aed-b2cd-44d5-aad6-4b4694edf6bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully to ../models//RandomForestClassifier_20240129011505.pkl\n",
      "Model Accuracy: 1.0\n",
      "\n",
      "Confusion Matrix:\n",
      "[[37837     0]\n",
      " [    0 87459]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     37837\n",
      "           1       1.00      1.00      1.00     87459\n",
      "\n",
      "    accuracy                           1.00    125296\n",
      "   macro avg       1.00      1.00      1.00    125296\n",
      "weighted avg       1.00      1.00      1.00    125296\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    pd, np, plt, sns, train_test_split, StandardScaler, RandomForestClassifier, accuracy_score, confusion_matrix, classification_report = import_churn_libraries()\n",
    "\n",
    "    \n",
    "    # Load data\n",
    "    file_path = \"../data/raw/new_raw.csv\"  \n",
    "    data = load_data(file_path)\n",
    "\n",
    "    # Preprocess data\n",
    "    preprocessed_data = preprocess_data(data)\n",
    "\n",
    "    # Feature engineering\n",
    "    engineered_data = feature_engineering(preprocessed_data)\n",
    "    \n",
    "    # Add 'churn' column\n",
    "    df_churned = add_churn_column(engineered_data)\n",
    "    \n",
    "    features = df_churned[['account_number', 'txn_amount', 'txn_month',\n",
    "       'txn_day', 'txn_type_add_money', 'txn_type_cash_in',\n",
    "       'txn_type_cash_out', 'txn_type_payment', 'txn_type_send_money',\n",
    "       'churn']]\n",
    "\n",
    "    target = 'churn'\n",
    "    \n",
    "    # Split data    \n",
    "    X_train, X_test, y_train, y_test = split_data(features)\n",
    "\n",
    "    # Choose and train the model\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    trained_model = train_model(model, X_train, y_train)\n",
    "\n",
    "    # Save the trained model\n",
    "    save_model(trained_model, model_name=\"RandomForestClassifier\", directory=\"../models/\")\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy, conf_matrix, class_report = evaluate_model(trained_model, X_test, y_test)\n",
    "\n",
    "    # Display results\n",
    "    print(f\"Model Accuracy: {accuracy}\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(class_report)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7824b4c7-cc17-40bb-b803-1dccc7d495fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
